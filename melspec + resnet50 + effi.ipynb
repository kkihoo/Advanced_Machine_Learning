{"cells":[{"cell_type":"markdown","metadata":{"id":"6DEodDI9MkKJ"},"source":["# create spectrogram images"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":5024,"status":"ok","timestamp":1713939995264,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"xd4lx1GWdM1t"},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","import torch\n","import torchaudio\n","import torchaudio.transforms as T\n","import librosa\n","import librosa.display\n","import IPython.display as ipd\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713939997520,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"VJk4ziUObTs-","outputId":"cf66796c-7842-40c6-9cb7-476e5880c58a"},"outputs":[{"name":"stdout","output_type":"stream","text":["train healthy   : 532 audios\n","train_pathology : 762 audios\n","test_healthy    : 100 audios\n","test_pathology  : 100 audios\n"]}],"source":["# 파일 개수 확인\n","train_healthy_paths = list(glob.glob('./SVD/train/healthy/*.wav'))\n","train_pathology_paths = list(glob.glob('./SVD/train/pathology/*.wav'))\n","test_healthy_paths = list(glob.glob('./SVD/test/healthy/*.wav'))\n","test_pathology_paths = list(glob.glob('./SVD/test/pathology/*.wav'))\n","print(f'train healthy   : {len(train_healthy_paths)} audios')\n","print(f'train_pathology : {len(train_pathology_paths)} audios')\n","print(f'test_healthy    : {len(test_healthy_paths)} audios')\n","print(f'test_pathology  : {len(test_pathology_paths)} audios')"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1713940029708,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"h-uEpQXO04co"},"outputs":[],"source":["# dataset 정의\n","def load_audios(paths):\n","\n","    paths = paths\n","    dataset = []\n","    for p in paths:\n","        name = os.path.basename(p)\n","        name = os.path.splitext(name)[0]\n","        waveform, sample_rate = torchaudio.load(p)\n","        dataset.append([waveform, sample_rate, name])\n","\n","    return dataset"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":23629,"status":"ok","timestamp":1713940055739,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"4QaYib0LA5rZ"},"outputs":[],"source":["# dataset 생성\n","h_train = load_audios(train_healthy_paths)\n","p_train = load_audios(train_pathology_paths)\n","h_test = load_audios(test_healthy_paths)\n","p_test = load_audios(test_pathology_paths)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1713940055740,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"m0B9pXWXBChr"},"outputs":[],"source":["# dataloader\n","loader_h_train = DataLoader(h_train, batch_size=1, shuffle=False)\n","loader_p_train = DataLoader(p_train, batch_size=1, shuffle=False)\n","loader_h_test = DataLoader(h_test, batch_size=1, shuffle=False)\n","loader_p_test = DataLoader(p_test, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1713940055740,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"Y84xH-Q8CKmK"},"outputs":[],"source":["def create_melspectrogram_images(loader, label, t):\n","    dir = f'./SVD/melspectrograms/{t}/{label}'\n","    os.makedirs(dir, exist_ok=True)\n","    \n","    for data in loader:\n","        waveform = data[0][0]\n","        sample_rate = data[1][0]\n","        name = data[2][0]\n","        \n","        melspectrogram = T.MelSpectrogram(sample_rate=sample_rate, n_fft=2048, hop_length=512, n_mels=128)\n","        mel_spec = melspectrogram(waveform)\n","        \n","        plt.figure(figsize=(10, 4))\n","        plt.imshow(librosa.power_to_db(mel_spec.squeeze().numpy(), ref=np.max), aspect='auto', origin='lower')\n","        plt.axis('off')\n","        plt.tight_layout(pad=0)\n","        plt.savefig(f'./SVD/melspectrograms/{t}/{label}/{name}.png', bbox_inches='tight', pad_inches=0)\n","        plt.close()"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":291375,"status":"ok","timestamp":1713940347106,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"70cGxHkYGTwi"},"outputs":[],"source":["# spectrogram image 생성 (5분 정도 소요)\n","create_melspectrogram_images(loader_h_train, 'healthy', 'train')\n","create_melspectrogram_images(loader_p_train, 'pathology', 'train')\n","create_melspectrogram_images(loader_h_test, 'healthy', 'test')\n","create_melspectrogram_images(loader_p_test, 'pathology', 'test')"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["# 데이터 증강 함수 정의\n","def augmentation(mel_spec_tensor):\n","    # 주파수 마스킹\n","    freq_masking = T.FrequencyMasking(freq_mask_param=30)\n","    mel_spec_tensor = freq_masking(mel_spec_tensor)\n","    \n","    # 시간 마스킹\n","    time_masking = T.TimeMasking(time_mask_param=40)\n","    mel_spec_tensor = time_masking(mel_spec_tensor)\n","    \n","    return mel_spec_tensor\n","\n","def create_augmented_melspectrogram_images(image_paths, label, t, augmentation_ratio):\n","    dir_aug = f'./SVD/melspectrograms/{t}/{label}'\n","    os.makedirs(dir_aug, exist_ok=True)\n","\n","    augmented_count = int(len(image_paths) * augmentation_ratio)\n","\n","    for i, image_path in enumerate(image_paths):\n","        if i >= augmented_count:\n","            break\n","        mel_spec = plt.imread(image_path)\n","        \n","        if mel_spec.ndim == 3 and mel_spec.shape[2] == 4:\n","            mel_spec = mel_spec[:, :, :3]  # RGBA -> RGB\n","        \n","        mel_spec_tensor = torch.from_numpy(mel_spec).permute(2, 0, 1).unsqueeze(0).float()\n","        \n","        augmented_mel_spec = augmentation(mel_spec_tensor)\n","        augmented_mel_spec_np = augmented_mel_spec.squeeze().permute(1, 2, 0).numpy()\n","        \n","        name = os.path.splitext(os.path.basename(image_path))[0]\n","        \n","        plt.imsave(f'./SVD/melspectrograms/{t}/{label}/{name}_augmented.png', augmented_mel_spec_np, cmap='viridis')\n","\n","# 원본 이미지 경로\n","healthy_image_dir = 'SVD/melspectrograms/train/healthy'\n","pathology_image_dir = 'SVD/melspectrograms/train/pathology'\n","\n","# 원본 이미지 경로 리스트\n","healthy_paths = [os.path.join(healthy_image_dir, f) for f in os.listdir(healthy_image_dir) if f.endswith('.png')]\n","pathology_paths = [os.path.join(pathology_image_dir, f) for f in os.listdir(pathology_image_dir) if f.endswith('.png')]\n","\n","# 증강된 spectrogram image 생성\n","create_augmented_melspectrogram_images(healthy_paths, 'healthy', 'train', augmentation_ratio=1)\n","create_augmented_melspectrogram_images(pathology_paths, 'pathology', 'train', augmentation_ratio=1)"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713940347107,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"c7z_Gwk0HBfs","outputId":"574ee91f-d5b0-47be-d642-562e4d6baa1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["train healthy   : 1064 images\n","train_pathology : 1524 images\n","test_healthy    : 100 images\n","test_pathology  : 100 images\n"]}],"source":["# 파일 개수 확인\n","train_healthy_images = list(glob.glob('./SVD/melspectrograms/train/healthy/*.png'))\n","train_pathology_images = list(glob.glob('./SVD/melspectrograms/train/pathology/*.png'))\n","test_healthy_images = list(glob.glob('./SVD/melspectrograms/test/healthy/*.png'))\n","test_pathology_images = list(glob.glob('./SVD/melspectrograms/test/pathology/*.png'))\n","print(f'train healthy   : {len(train_healthy_images)} images')\n","print(f'train_pathology : {len(train_pathology_images)} images')\n","print(f'test_healthy    : {len(test_healthy_images)} images')\n","print(f'test_pathology  : {len(test_pathology_images)} images')"]},{"cell_type":"markdown","metadata":{"id":"RubAPLKTQSaY"},"source":["# classification"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset ImageFolder\n","    Number of datapoints: 2588\n","    Root location: ./SVD/melspectrograms/train\n","    StandardTransform\n","Transform: Compose(\n","               ToTensor()\n","               Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=True)\n","           )\n","\n","class : index\n","{'healthy': 0, 'pathology': 1}\n","Dataset ImageFolder\n","    Number of datapoints: 200\n","    Root location: ./SVD/melspectrograms/test\n","    StandardTransform\n","Transform: Compose(\n","               ToTensor()\n","               Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=True)\n","           )\n","\n","class : index\n","{'healthy': 0, 'pathology': 1}\n"]}],"source":["import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","\n","# trainset\n","train_path = './SVD/melspectrograms/train'\n","trainset = ImageFolder(root=train_path, transform=transforms.Compose([transforms.ToTensor(),\n","                                                                    transforms.Resize((256, 256))]))\n","print(trainset)\n","print(f'\\nclass : index\\n{trainset.class_to_idx}')\n","\n","# testset\n","test_path = './SVD/melspectrograms/test'\n","testset = ImageFolder(root=test_path, transform=transforms.Compose([transforms.ToTensor(),\n","                                                                    transforms.Resize((256, 256))]))\n","print(testset)\n","print(f'\\nclass : index\\n{testset.class_to_idx}')\n","\n","# dataloader\n","train_dataloader = DataLoader(trainset, batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(testset, batch_size=16, shuffle=False)\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713940363069,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"BZNJZxw3WJOL","outputId":"287aad94-0cda-4fda-c024-1e84cb73f3eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n","Using mps device\n"]}],"source":["# GPU\n","print(torch.backends.mps.is_built())\n","print(torch.backends.mps.is_available()) \n","\n","device = torch.device(\"mps\")\n","print(f'Using {device} device')"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# 사전학습모델 불러오기\n","import numpy as np\n","from torchvision.models import resnet50, ResNet50_Weights, efficientnet_b0, EfficientNet_B0_Weights\n","\n","# ResNet50 모델\n","resnet50_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n","resnet50_model.fc = nn.Sequential(\n","    nn.Dropout(p=0.5),\n","    nn.Linear(2048, 2)\n",")\n","# EfficientNet-B0 모델\n","efficientnet_b0_model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n","efficientnet_b0_model.classifier = nn.Sequential(\n","    nn.Dropout(p=0.5),\n","    nn.Linear(1280, 2)\n",")\n","\n","# 모델, 손실함수, 옵티마이저\n","resnet50_model = resnet50_model.to(device)\n","efficientnet_b0_model = efficientnet_b0_model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","resnet50_optimizer = optim.Adam(resnet50_model.parameters(), lr=0.0005)\n","efficientnet_b0_optimizer = optim.Adam(efficientnet_b0_model.parameters(), lr=0.0005)\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[epoch: 1 / batch:  10] loss: 0.6287, accuracy: 64.69%\n","[epoch: 1 / batch:  20] loss: 0.5090, accuracy: 74.06%\n","[epoch: 1 / batch:  30] loss: 0.4770, accuracy: 70.62%\n","[epoch: 1 / batch:  40] loss: 0.4609, accuracy: 79.38%\n","[epoch: 1 / batch:  50] loss: 0.3947, accuracy: 82.50%\n","[epoch: 1 / batch:  60] loss: 0.4033, accuracy: 82.50%\n","[epoch: 1 / batch:  70] loss: 0.3278, accuracy: 84.38%\n","[epoch: 1 / batch:  80] loss: 0.3431, accuracy: 84.38%\n","[epoch: 2 / batch:  10] loss: 0.2698, accuracy: 87.81%\n","[epoch: 2 / batch:  20] loss: 0.2144, accuracy: 90.62%\n","[epoch: 2 / batch:  30] loss: 0.2925, accuracy: 85.94%\n","[epoch: 2 / batch:  40] loss: 0.2419, accuracy: 93.12%\n","[epoch: 2 / batch:  50] loss: 0.3277, accuracy: 89.69%\n","[epoch: 2 / batch:  60] loss: 0.2834, accuracy: 87.19%\n","[epoch: 2 / batch:  70] loss: 0.2335, accuracy: 90.31%\n","[epoch: 2 / batch:  80] loss: 0.1880, accuracy: 93.75%\n","[epoch: 3 / batch:  10] loss: 0.1461, accuracy: 94.38%\n","[epoch: 3 / batch:  20] loss: 0.1259, accuracy: 95.94%\n","[epoch: 3 / batch:  30] loss: 0.1025, accuracy: 94.69%\n","[epoch: 3 / batch:  40] loss: 0.1238, accuracy: 95.31%\n","[epoch: 3 / batch:  50] loss: 0.0873, accuracy: 95.31%\n","[epoch: 3 / batch:  60] loss: 0.1602, accuracy: 95.00%\n","[epoch: 3 / batch:  70] loss: 0.2281, accuracy: 91.88%\n","[epoch: 3 / batch:  80] loss: 0.1627, accuracy: 93.12%\n","[epoch: 4 / batch:  10] loss: 0.0977, accuracy: 97.19%\n","[epoch: 4 / batch:  20] loss: 0.0869, accuracy: 96.56%\n","[epoch: 4 / batch:  30] loss: 0.0782, accuracy: 97.19%\n","[epoch: 4 / batch:  40] loss: 0.0471, accuracy: 97.81%\n","[epoch: 4 / batch:  50] loss: 0.0587, accuracy: 98.12%\n","[epoch: 4 / batch:  60] loss: 0.0462, accuracy: 98.44%\n","[epoch: 4 / batch:  70] loss: 0.0296, accuracy: 99.06%\n","[epoch: 4 / batch:  80] loss: 0.0475, accuracy: 98.44%\n","[epoch: 5 / batch:  10] loss: 0.0295, accuracy: 99.06%\n","[epoch: 5 / batch:  20] loss: 0.0629, accuracy: 98.12%\n","[epoch: 5 / batch:  30] loss: 0.0712, accuracy: 97.50%\n","[epoch: 5 / batch:  40] loss: 0.1029, accuracy: 96.88%\n","[epoch: 5 / batch:  50] loss: 0.0947, accuracy: 95.94%\n","[epoch: 5 / batch:  60] loss: 0.0994, accuracy: 95.31%\n","[epoch: 5 / batch:  70] loss: 0.0937, accuracy: 95.94%\n","[epoch: 5 / batch:  80] loss: 0.1005, accuracy: 97.50%\n","[epoch: 6 / batch:  10] loss: 0.1048, accuracy: 96.25%\n","[epoch: 6 / batch:  20] loss: 0.0795, accuracy: 97.81%\n","[epoch: 6 / batch:  30] loss: 0.1239, accuracy: 94.38%\n","[epoch: 6 / batch:  40] loss: 0.0633, accuracy: 98.44%\n","[epoch: 6 / batch:  50] loss: 0.0931, accuracy: 95.94%\n","[epoch: 6 / batch:  60] loss: 0.1544, accuracy: 94.69%\n","[epoch: 6 / batch:  70] loss: 0.0572, accuracy: 98.44%\n","[epoch: 6 / batch:  80] loss: 0.0700, accuracy: 97.81%\n","[epoch: 7 / batch:  10] loss: 0.0262, accuracy: 99.06%\n","[epoch: 7 / batch:  20] loss: 0.0292, accuracy: 99.38%\n","[epoch: 7 / batch:  30] loss: 0.0260, accuracy: 98.75%\n","[epoch: 7 / batch:  40] loss: 0.0189, accuracy: 99.38%\n","[epoch: 7 / batch:  50] loss: 0.0210, accuracy: 99.06%\n","[epoch: 7 / batch:  60] loss: 0.0142, accuracy: 99.69%\n","[epoch: 7 / batch:  70] loss: 0.0090, accuracy: 100.00%\n","[epoch: 7 / batch:  80] loss: 0.0050, accuracy: 100.00%\n","[epoch: 8 / batch:  10] loss: 0.0113, accuracy: 99.69%\n","[epoch: 8 / batch:  20] loss: 0.0055, accuracy: 100.00%\n","[epoch: 8 / batch:  30] loss: 0.0164, accuracy: 99.69%\n","[epoch: 8 / batch:  40] loss: 0.0050, accuracy: 100.00%\n","[epoch: 8 / batch:  50] loss: 0.0096, accuracy: 99.69%\n","[epoch: 8 / batch:  60] loss: 0.0040, accuracy: 100.00%\n","[epoch: 8 / batch:  70] loss: 0.0045, accuracy: 99.69%\n","[epoch: 8 / batch:  80] loss: 0.0087, accuracy: 99.69%\n","[epoch: 9 / batch:  10] loss: 0.0076, accuracy: 99.69%\n","[epoch: 9 / batch:  20] loss: 0.0059, accuracy: 99.69%\n","[epoch: 9 / batch:  30] loss: 0.0014, accuracy: 100.00%\n","[epoch: 9 / batch:  40] loss: 0.0114, accuracy: 99.38%\n","[epoch: 9 / batch:  50] loss: 0.0268, accuracy: 99.38%\n","[epoch: 9 / batch:  60] loss: 0.0127, accuracy: 99.69%\n","[epoch: 9 / batch:  70] loss: 0.0032, accuracy: 100.00%\n","[epoch: 9 / batch:  80] loss: 0.0078, accuracy: 99.69%\n","[epoch: 10 / batch:  10] loss: 0.0079, accuracy: 100.00%\n","[epoch: 10 / batch:  20] loss: 0.0059, accuracy: 100.00%\n","[epoch: 10 / batch:  30] loss: 0.0048, accuracy: 99.69%\n","[epoch: 10 / batch:  40] loss: 0.0129, accuracy: 99.38%\n","[epoch: 10 / batch:  50] loss: 0.0167, accuracy: 99.38%\n","[epoch: 10 / batch:  60] loss: 0.0383, accuracy: 98.75%\n","[epoch: 10 / batch:  70] loss: 0.0466, accuracy: 98.44%\n","[epoch: 10 / batch:  80] loss: 0.0740, accuracy: 98.12%\n","Finished Training\n","[epoch: 1 / batch:  10] loss: 0.0622, accuracy: 64.38%\n","[epoch: 1 / batch:  20] loss: 0.0467, accuracy: 79.69%\n","[epoch: 1 / batch:  30] loss: 0.0479, accuracy: 76.56%\n","[epoch: 1 / batch:  40] loss: 0.0439, accuracy: 81.25%\n","[epoch: 1 / batch:  50] loss: 0.0381, accuracy: 83.75%\n","[epoch: 1 / batch:  60] loss: 0.0389, accuracy: 79.69%\n","[epoch: 1 / batch:  70] loss: 0.0376, accuracy: 82.81%\n","[epoch: 1 / batch:  80] loss: 0.0329, accuracy: 85.00%\n","[epoch: 2 / batch:  10] loss: 0.0247, accuracy: 88.44%\n","[epoch: 2 / batch:  20] loss: 0.0164, accuracy: 94.38%\n","[epoch: 2 / batch:  30] loss: 0.0163, accuracy: 93.75%\n","[epoch: 2 / batch:  40] loss: 0.0229, accuracy: 90.31%\n","[epoch: 2 / batch:  50] loss: 0.0186, accuracy: 92.50%\n","[epoch: 2 / batch:  60] loss: 0.0194, accuracy: 91.88%\n","[epoch: 2 / batch:  70] loss: 0.0154, accuracy: 92.81%\n","[epoch: 2 / batch:  80] loss: 0.0143, accuracy: 94.69%\n","[epoch: 3 / batch:  10] loss: 0.0137, accuracy: 96.56%\n","[epoch: 3 / batch:  20] loss: 0.0100, accuracy: 94.69%\n","[epoch: 3 / batch:  30] loss: 0.0136, accuracy: 95.00%\n","[epoch: 3 / batch:  40] loss: 0.0113, accuracy: 95.94%\n","[epoch: 3 / batch:  50] loss: 0.0118, accuracy: 94.69%\n","[epoch: 3 / batch:  60] loss: 0.0063, accuracy: 97.50%\n","[epoch: 3 / batch:  70] loss: 0.0148, accuracy: 95.00%\n","[epoch: 3 / batch:  80] loss: 0.0107, accuracy: 95.62%\n","[epoch: 4 / batch:  10] loss: 0.0082, accuracy: 96.25%\n","[epoch: 4 / batch:  20] loss: 0.0099, accuracy: 96.88%\n","[epoch: 4 / batch:  30] loss: 0.0082, accuracy: 98.12%\n","[epoch: 4 / batch:  40] loss: 0.0062, accuracy: 97.19%\n","[epoch: 4 / batch:  50] loss: 0.0115, accuracy: 95.94%\n","[epoch: 4 / batch:  60] loss: 0.0064, accuracy: 96.88%\n","[epoch: 4 / batch:  70] loss: 0.0059, accuracy: 97.50%\n","[epoch: 4 / batch:  80] loss: 0.0072, accuracy: 96.56%\n","[epoch: 5 / batch:  10] loss: 0.0077, accuracy: 97.81%\n","[epoch: 5 / batch:  20] loss: 0.0043, accuracy: 98.44%\n","[epoch: 5 / batch:  30] loss: 0.0025, accuracy: 99.06%\n","[epoch: 5 / batch:  40] loss: 0.0057, accuracy: 97.81%\n","[epoch: 5 / batch:  50] loss: 0.0056, accuracy: 98.12%\n","[epoch: 5 / batch:  60] loss: 0.0058, accuracy: 97.50%\n","[epoch: 5 / batch:  70] loss: 0.0042, accuracy: 98.12%\n","[epoch: 5 / batch:  80] loss: 0.0056, accuracy: 98.44%\n","[epoch: 6 / batch:  10] loss: 0.0047, accuracy: 98.44%\n","[epoch: 6 / batch:  20] loss: 0.0060, accuracy: 98.12%\n","[epoch: 6 / batch:  30] loss: 0.0043, accuracy: 97.81%\n","[epoch: 6 / batch:  40] loss: 0.0052, accuracy: 97.50%\n","[epoch: 6 / batch:  50] loss: 0.0039, accuracy: 98.75%\n","[epoch: 6 / batch:  60] loss: 0.0023, accuracy: 99.06%\n","[epoch: 6 / batch:  70] loss: 0.0070, accuracy: 97.19%\n","[epoch: 6 / batch:  80] loss: 0.0092, accuracy: 96.88%\n","[epoch: 7 / batch:  10] loss: 0.0038, accuracy: 98.44%\n","[epoch: 7 / batch:  20] loss: 0.0085, accuracy: 97.81%\n","[epoch: 7 / batch:  30] loss: 0.0049, accuracy: 99.06%\n","[epoch: 7 / batch:  40] loss: 0.0027, accuracy: 99.38%\n","[epoch: 7 / batch:  50] loss: 0.0033, accuracy: 99.06%\n","[epoch: 7 / batch:  60] loss: 0.0021, accuracy: 99.38%\n","[epoch: 7 / batch:  70] loss: 0.0018, accuracy: 99.69%\n","[epoch: 7 / batch:  80] loss: 0.0033, accuracy: 98.44%\n","[epoch: 8 / batch:  10] loss: 0.0026, accuracy: 99.06%\n","[epoch: 8 / batch:  20] loss: 0.0052, accuracy: 97.81%\n","[epoch: 8 / batch:  30] loss: 0.0065, accuracy: 98.12%\n","[epoch: 8 / batch:  40] loss: 0.0081, accuracy: 96.56%\n","[epoch: 8 / batch:  50] loss: 0.0021, accuracy: 99.69%\n","[epoch: 8 / batch:  60] loss: 0.0028, accuracy: 99.06%\n","[epoch: 8 / batch:  70] loss: 0.0025, accuracy: 99.69%\n","[epoch: 8 / batch:  80] loss: 0.0020, accuracy: 99.38%\n","[epoch: 9 / batch:  10] loss: 0.0007, accuracy: 100.00%\n","[epoch: 9 / batch:  20] loss: 0.0029, accuracy: 98.75%\n","[epoch: 9 / batch:  30] loss: 0.0026, accuracy: 98.44%\n","[epoch: 9 / batch:  40] loss: 0.0025, accuracy: 99.06%\n","[epoch: 9 / batch:  50] loss: 0.0021, accuracy: 99.69%\n","[epoch: 9 / batch:  60] loss: 0.0059, accuracy: 97.50%\n","[epoch: 9 / batch:  70] loss: 0.0018, accuracy: 99.38%\n","[epoch: 9 / batch:  80] loss: 0.0010, accuracy: 99.69%\n","[epoch: 10 / batch:  10] loss: 0.0015, accuracy: 99.69%\n","[epoch: 10 / batch:  20] loss: 0.0004, accuracy: 100.00%\n","[epoch: 10 / batch:  30] loss: 0.0010, accuracy: 99.69%\n","[epoch: 10 / batch:  40] loss: 0.0004, accuracy: 100.00%\n","[epoch: 10 / batch:  50] loss: 0.0041, accuracy: 98.44%\n","[epoch: 10 / batch:  60] loss: 0.0014, accuracy: 99.06%\n","[epoch: 10 / batch:  70] loss: 0.0010, accuracy: 99.38%\n","[epoch: 10 / batch:  80] loss: 0.0043, accuracy: 98.75%\n","Finished Training\n"]}],"source":["# resnet training\n","for epoch in range(10):\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    \n","    for i, data in enumerate(train_dataloader):\n","        images, labels = data[0].to(device), data[1].to(device)\n","        resnet50_optimizer.zero_grad()\n","        outputs = resnet50_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        resnet50_optimizer.step()\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        if (i + 1) % 10 == 0:\n","            accuracy = 100 * correct / total\n","            print(f'[epoch: {epoch+1} / batch: {i+1:3d}] loss: {running_loss/10:.4f}, accuracy: {accuracy:.2f}%')\n","            running_loss = 0.0\n","            correct = 0\n","            total = 0\n","\n","print('Finished Training')\n","\n","# efficient training \n","for epoch in range(10):\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for i, data in enumerate(train_dataloader):\n","        images, labels = data[0].to(device), data[1].to(device)\n","        efficientnet_b0_optimizer.zero_grad()\n","        outputs = efficientnet_b0_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        efficientnet_b0_optimizer.step()\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        if (i + 1) % 10 == 0:\n","            accuracy = 100 * correct / total\n","            print(f'[epoch: {epoch+1} / batch: {i+1:3d}] loss: {running_loss/100:.4f}, accuracy: {accuracy:.2f}%')\n","            running_loss = 0.0\n","            correct = 0\n","            total = 0\n","\n","print('Finished Training')\n","\n","# ResNet50 모델 저장\n","resnet50_path = './SVD/resnet50_model.pth'\n","torch.save(resnet50_model.state_dict(), resnet50_path)\n","\n","# EfficientNet-B0 모델 저장\n","efficientnet_b0_path = './SVD/efficientnet_b0_model.pth'\n","torch.save(efficientnet_b0_model.state_dict(), efficientnet_b0_path)\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Weights: ResNet50 = 0.45, EfficientNet-B0 = 0.55\n","[[84 16]\n"," [23 77]]\n","accuracy: 0.8050, recall: 0.7700, precision: 0.8280, f1: 0.7979\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","\n","# 테스트 데이터에 대한 예측 결과 얻기\n","def confusion(resnet50_model, efficientnet_b0_model, loader, resnet50_weight, efficientnet_b0_weight):\n","    y_true = []\n","    ensemble_preds = []\n","    \n","    resnet50_model.eval()\n","    efficientnet_b0_model.eval()\n","    \n","    with torch.no_grad():\n","        for data in loader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            resnet50_outputs = resnet50_model(images)\n","            efficientnet_b0_outputs = efficientnet_b0_model(images)\n","            \n","            # Softmax 함수 적용하여 정규화\n","            resnet50_probabilities = nn.functional.softmax(resnet50_outputs, dim=1)\n","            efficientnet_b0_probabilities = nn.functional.softmax(efficientnet_b0_outputs, dim=1)\n","            \n","            ensemble_probabilities = (resnet50_weight * resnet50_probabilities) + (efficientnet_b0_weight * efficientnet_b0_probabilities)\n","            preds = torch.argmax(ensemble_probabilities, dim=1)\n","            \n","            y_true.extend(labels.tolist())\n","            ensemble_preds.extend(preds.tolist())\n","    \n","    cm = confusion_matrix(y_true, ensemble_preds)\n","    return cm\n","\n","# 가중치 탐색 함수\n","def weight_search(resnet50_model, efficientnet_b0_model, loader):\n","    best_accuracy = 0\n","    best_weights = None\n","    best_metrics = None\n","\n","    # 가중치 범위 설정 (0.3 ~ 0.7)\n","    weight_range = np.arange(0.3, 0.71, 0.05)\n","    for resnet50_weight in weight_range:\n","        efficientnet_b0_weight = 1 - resnet50_weight\n","        # 주어진 가중치로 평가\n","        cm = confusion(resnet50_model, efficientnet_b0_model, loader, resnet50_weight, efficientnet_b0_weight)\n","        accuracy, recall, precision, f1 = metrics(cm)\n","        # 최고 accuracy 갱신\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","            best_weights = (resnet50_weight, efficientnet_b0_weight)\n","            best_metrics = (accuracy, recall, precision, f1)\n","\n","    return best_weights, best_metrics\n","\n","# metrics 계산 함수\n","def metrics(cm):\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","    recall = (tp) / (tp + fn)\n","    precision = (tp) / (tp + fp)\n","    f1 = (2 * recall * precision) / (recall + precision)\n","\n","    return accuracy, recall, precision, f1\n","\n","# 최적 가중치 탐색\n","best_weights, best_metrics = weight_search(resnet50_model, efficientnet_b0_model, test_dataloader)\n","best_resnet50_weight, best_efficientnet_b0_weight = best_weights\n","\n","# 최적 가중치로 confusion matrix 계산\n","cm = confusion(resnet50_model, efficientnet_b0_model, test_dataloader, best_resnet50_weight, best_efficientnet_b0_weight)\n","\n","# 최적 가중치와 confusion matrix 출력\n","print(f\"Best Weights: ResNet50 = {best_resnet50_weight:.2f}, EfficientNet-B0 = {best_efficientnet_b0_weight:.2f}\")\n","print(cm)\n","\n","# 최적 가중치로 계산된 metrics 출력\n","accuracy, recall, precision, f1 = best_metrics\n","print(f'accuracy: {accuracy:.4f}, recall: {recall:.4f}, precision: {precision:.4f}, f1: {f1:.4f}')"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[83 17]\n"," [23 77]]\n","accuracy: 0.8000, recall: 0.7700, precision: 0.8191, f1: 0.7938\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","\n","# confusion matrix\n","def confusion(resnet50_model, efficientnet_b0_model, loader, weights):\n","    y_true = []\n","    ensemble_preds = []\n","    resnet50_model.eval()\n","    efficientnet_b0_model.eval()\n","    with torch.no_grad():\n","        for data in loader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            resnet50_outputs = resnet50_model(images)\n","            efficientnet_b0_outputs = efficientnet_b0_model(images)\n","            # Softmax \n","            resnet50_probabilities = nn.functional.softmax(resnet50_outputs, dim=1)\n","            efficientnet_b0_probabilities = nn.functional.softmax(efficientnet_b0_outputs, dim=1)\n","            ensemble_probabilities = (weights[0] * resnet50_probabilities) + (weights[1] * efficientnet_b0_probabilities)\n","            preds = torch.argmax(ensemble_probabilities, dim=1)\n","            y_true.extend(labels.tolist())\n","            ensemble_preds.extend(preds.tolist())\n","    cm = confusion_matrix(y_true, ensemble_preds)\n","    return cm\n","\n","# confusion matrix\n","weights = [0.4,0.6]  # ResNet50, EfficientNet-B0\n","cm = confusion(resnet50_model, efficientnet_b0_model, test_dataloader, weights)\n","print(cm)\n","\n","# metrics\n","def metrics(cm):\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","    recall = (tp) / (tp + fn)\n","    precision = (tp) / (tp + fp)\n","    f1 = (2 * recall * precision) / (recall + precision)\n","    print(f'accuracy: {accuracy:.4f}, recall: {recall:.4f}, precision: {precision:.4f}, f1: {f1:.4f}')\n","    return accuracy, recall, precision, f1\n","\n","# metrics\n","accuracy, recall, precision, f1 = metrics(cm)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
