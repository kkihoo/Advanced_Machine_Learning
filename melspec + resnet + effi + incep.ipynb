{"cells":[{"cell_type":"markdown","metadata":{"id":"6DEodDI9MkKJ"},"source":["# create spectrogram images"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5024,"status":"ok","timestamp":1713939995264,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"xd4lx1GWdM1t"},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","import torch\n","import torchaudio\n","import torchaudio.transforms as T\n","import librosa\n","import librosa.display\n","import IPython.display as ipd\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713939997520,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"VJk4ziUObTs-","outputId":"cf66796c-7842-40c6-9cb7-476e5880c58a"},"outputs":[],"source":["# 파일 개수 확인\n","train_healthy_paths = list(glob.glob('./SVD/train/healthy/*.wav'))\n","train_pathology_paths = list(glob.glob('./SVD/train/pathology/*.wav'))\n","test_healthy_paths = list(glob.glob('./SVD/test/healthy/*.wav'))\n","test_pathology_paths = list(glob.glob('./SVD/test/pathology/*.wav'))\n","print(f'train healthy   : {len(train_healthy_paths)} audios')\n","print(f'train_pathology : {len(train_pathology_paths)} audios')\n","print(f'test_healthy    : {len(test_healthy_paths)} audios')\n","print(f'test_pathology  : {len(test_pathology_paths)} audios')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1713940029708,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"h-uEpQXO04co"},"outputs":[],"source":["# dataset 정의\n","def load_audios(paths):\n","\n","    paths = paths\n","    dataset = []\n","    for p in paths:\n","        name = os.path.basename(p)\n","        name = os.path.splitext(name)[0]\n","        waveform, sample_rate = torchaudio.load(p)\n","        dataset.append([waveform, sample_rate, name])\n","\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23629,"status":"ok","timestamp":1713940055739,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"4QaYib0LA5rZ"},"outputs":[],"source":["# dataset 생성\n","h_train = load_audios(train_healthy_paths)\n","p_train = load_audios(train_pathology_paths)\n","h_test = load_audios(test_healthy_paths)\n","p_test = load_audios(test_pathology_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1713940055740,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"m0B9pXWXBChr"},"outputs":[],"source":["# dataloader\n","loader_h_train = DataLoader(h_train, batch_size=1, shuffle=False)\n","loader_p_train = DataLoader(p_train, batch_size=1, shuffle=False)\n","loader_h_test = DataLoader(h_test, batch_size=1, shuffle=False)\n","loader_p_test = DataLoader(p_test, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1713940055740,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"Y84xH-Q8CKmK"},"outputs":[],"source":["def create_melspectrogram_images(loader, label, t):\n","    dir = f'./SVD/melspectrograms/{t}/{label}'\n","    os.makedirs(dir, exist_ok=True)\n","    \n","    for data in loader:\n","        waveform = data[0][0]\n","        sample_rate = data[1][0]\n","        name = data[2][0]\n","        \n","        melspectrogram = T.MelSpectrogram(sample_rate=sample_rate, n_fft=512, hop_length=512, n_mels=128)\n","        mel_spec = melspectrogram(waveform)\n","        \n","        plt.figure(figsize=(10, 4))\n","        plt.imshow(librosa.power_to_db(mel_spec.squeeze().numpy(), ref=np.max), aspect='auto', origin='lower')\n","        plt.axis('off')\n","        plt.tight_layout(pad=0)\n","        plt.savefig(f'./SVD/melspectrograms/{t}/{label}/{name}.png', bbox_inches='tight', pad_inches=0)\n","        plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":291375,"status":"ok","timestamp":1713940347106,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"70cGxHkYGTwi"},"outputs":[],"source":["# spectrogram image 생성 (5분 정도 소요)\n","create_melspectrogram_images(loader_h_train, 'healthy', 'train')\n","create_melspectrogram_images(loader_p_train, 'pathology', 'train')\n","create_melspectrogram_images(loader_h_test, 'healthy', 'test')\n","create_melspectrogram_images(loader_p_test, 'pathology', 'test')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 데이터 증강 함수 정의\n","def augmentation(mel_spec_tensor):\n","    # 주파수 마스킹\n","    freq_masking = T.FrequencyMasking(freq_mask_param=30)\n","    mel_spec_tensor = freq_masking(mel_spec_tensor)\n","    \n","    # 시간 마스킹\n","    time_masking = T.TimeMasking(time_mask_param=40)\n","    mel_spec_tensor = time_masking(mel_spec_tensor)\n","    \n","    return mel_spec_tensor\n","\n","def create_augmented_melspectrogram_images(image_paths, label, t, augmentation_ratio):\n","    dir_aug = f'./SVD/melspectrograms/{t}/{label}'\n","    os.makedirs(dir_aug, exist_ok=True)\n","\n","    augmented_count = int(len(image_paths) * augmentation_ratio)\n","\n","    for i, image_path in enumerate(image_paths):\n","        if i >= augmented_count:\n","            break\n","        mel_spec = plt.imread(image_path)\n","        \n","        if mel_spec.ndim == 3 and mel_spec.shape[2] == 4:\n","            mel_spec = mel_spec[:, :, :3]  # RGBA -> RGB\n","        \n","        mel_spec_tensor = torch.from_numpy(mel_spec).permute(2, 0, 1).unsqueeze(0).float()\n","        \n","        augmented_mel_spec = augmentation(mel_spec_tensor)\n","        augmented_mel_spec_np = augmented_mel_spec.squeeze().permute(1, 2, 0).numpy()\n","        \n","        name = os.path.splitext(os.path.basename(image_path))[0]\n","        \n","        plt.imsave(f'./SVD/melspectrograms/{t}/{label}/{name}_augmented.png', augmented_mel_spec_np, cmap='viridis')\n","\n","# 원본 이미지 경로\n","healthy_image_dir = 'SVD/melspectrograms/train/healthy'\n","pathology_image_dir = 'SVD/melspectrograms/train/pathology'\n","\n","# 원본 이미지 경로 리스트\n","healthy_paths = [os.path.join(healthy_image_dir, f) for f in os.listdir(healthy_image_dir) if f.endswith('.png')]\n","pathology_paths = [os.path.join(pathology_image_dir, f) for f in os.listdir(pathology_image_dir) if f.endswith('.png')]\n","\n","# 증강된 spectrogram image 생성\n","create_augmented_melspectrogram_images(healthy_paths, 'healthy', 'train', augmentation_ratio=1)\n","create_augmented_melspectrogram_images(pathology_paths, 'pathology', 'train', augmentation_ratio=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713940347107,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"c7z_Gwk0HBfs","outputId":"574ee91f-d5b0-47be-d642-562e4d6baa1d"},"outputs":[],"source":["# 파일 개수 확인\n","train_healthy_images = list(glob.glob('./SVD/melspectrograms/train/healthy/*.png'))\n","train_pathology_images = list(glob.glob('./SVD/melspectrograms/train/pathology/*.png'))\n","test_healthy_images = list(glob.glob('./SVD/melspectrograms/test/healthy/*.png'))\n","test_pathology_images = list(glob.glob('./SVD/melspectrograms/test/pathology/*.png'))\n","print(f'train healthy   : {len(train_healthy_images)} images')\n","print(f'train_pathology : {len(train_pathology_images)} images')\n","print(f'test_healthy    : {len(test_healthy_images)} images')\n","print(f'test_pathology  : {len(test_pathology_images)} images')"]},{"cell_type":"markdown","metadata":{"id":"RubAPLKTQSaY"},"source":["# classification"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","\n","# trainset\n","train_path = './SVD/melspectrograms/train'\n","trainset = ImageFolder(root=train_path, transform=transforms.Compose([transforms.ToTensor(),\n","                                                                    transforms.Resize((299, 299))]))\n","print(trainset)\n","print(f'\\nclass : index\\n{trainset.class_to_idx}')\n","\n","# testset\n","test_path = './SVD/melspectrograms/test'\n","testset = ImageFolder(root=test_path, transform=transforms.Compose([transforms.ToTensor(),\n","                                                                    transforms.Resize((299, 299))]))\n","print(testset)\n","print(f'\\nclass : index\\n{testset.class_to_idx}')\n","\n","# dataloader\n","train_dataloader = DataLoader(trainset, batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(testset, batch_size=16, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713940363069,"user":{"displayName":"JH HONG","userId":"12244667994032889629"},"user_tz":-540},"id":"BZNJZxw3WJOL","outputId":"287aad94-0cda-4fda-c024-1e84cb73f3eb"},"outputs":[],"source":["# GPU\n","print(torch.backends.mps.is_built())\n","print(torch.backends.mps.is_available()) \n","\n","device = torch.device(\"mps\")\n","print(f'Using {device} device')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 사전학습모델 불러오기\n","import numpy as np\n","from torchvision.models import resnet50, ResNet50_Weights, efficientnet_b0, EfficientNet_B0_Weights, inception_v3, Inception_V3_Weights\n","\n","# ResNet50 모델\n","resnet50_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n","resnet50_model.fc = nn.Sequential(\n","    nn.Dropout(p=0.5),\n","    nn.Linear(2048, 2)\n",")\n","# EfficientNet-B0 모델\n","efficientnet_b0_model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n","efficientnet_b0_model.classifier = nn.Sequential(\n","    nn.Dropout(p=0.5),\n","    nn.Linear(1280, 2)\n",")\n","\n","# Inception-v3 모델\n","inception_v3_model = inception_v3(weights=Inception_V3_Weights.DEFAULT)\n","inception_v3_model.fc = nn.Sequential(\n","    nn.Dropout(p=0.5),\n","    nn.Linear(2048, 2)\n",")\n","\n","\n","# 모델, 손실함수, 옵티마이저\n","resnet50_model = resnet50_model.to(device)\n","efficientnet_b0_model = efficientnet_b0_model.to(device)\n","inception_v3_model = inception_v3_model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","resnet50_optimizer = optim.Adam(resnet50_model.parameters(), lr=0.0005)\n","efficientnet_b0_optimizer = optim.Adam(efficientnet_b0_model.parameters(), lr=0.0005)\n","inception_v3_optimizer = optim.Adam(inception_v3_model.parameters(), lr=0.0005)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# resnet training\n","for epoch in range(10):\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    \n","    for i, data in enumerate(train_dataloader):\n","        images, labels = data[0].to(device), data[1].to(device)\n","        resnet50_optimizer.zero_grad()\n","        outputs = resnet50_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        resnet50_optimizer.step()\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        if (i + 1) % 10 == 0:\n","            accuracy = 100 * correct / total\n","            print(f'[epoch: {epoch+1} / batch: {i+1:3d}] loss: {running_loss/10:.4f}, accuracy: {accuracy:.2f}%')\n","            running_loss = 0.0\n","            correct = 0\n","            total = 0\n","\n","print('Finished Training')\n","\n","# efficient training \n","for epoch in range(10):\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for i, data in enumerate(train_dataloader):\n","        images, labels = data[0].to(device), data[1].to(device)\n","        efficientnet_b0_optimizer.zero_grad()\n","        outputs = efficientnet_b0_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        efficientnet_b0_optimizer.step()\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        if (i + 1) % 10 == 0:\n","            accuracy = 100 * correct / total\n","            print(f'[epoch: {epoch+1} / batch: {i+1:3d}] loss: {running_loss/100:.4f}, accuracy: {accuracy:.2f}%')\n","            running_loss = 0.0\n","            correct = 0\n","            total = 0\n","\n","print('Finished Training')\n","\n","# Inception-v3 training\n","for epoch in range(10):\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for i, data in enumerate(train_dataloader):\n","        images, labels = data[0].to(device), data[1].to(device)\n","        inception_v3_optimizer.zero_grad()\n","        outputs = inception_v3_model(images)\n","        loss = criterion(outputs.logits, labels)\n","        loss.backward()\n","        inception_v3_optimizer.step()\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.logits.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        if (i + 1) % 10 == 0:\n","            accuracy = 100 * correct / total\n","            print(f'[epoch: {epoch+1} / batch: {i+1:3d}] loss: {running_loss/10:.4f}, accuracy: {accuracy:.2f}%')\n","            running_loss = 0.0\n","            correct = 0\n","            total = 0\n","\n","print('Finished Training Inception-v3')\n","\n","# ResNet50 모델 저장\n","resnet50_path = './SVD/resnet50_model.pth'\n","torch.save(resnet50_model.state_dict(), resnet50_path)\n","\n","# EfficientNet-B0 모델 저장\n","efficientnet_b0_path = './SVD/efficientnet_b0_model2.pth'\n","torch.save(efficientnet_b0_model.state_dict(), efficientnet_b0_path)\n","\n","# Inception-v3 모델 저장\n","inception_v3_path = './SVD/inception_v3_model.pth'\n","torch.save(inception_v3_model.state_dict(), inception_v3_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","# 테스트 데이터에 대한 예측 결과 얻기\n","def confusion(resnet50_model, efficientnet_b0_model, inception_v3_model, loader, weights):\n","    y_true = []\n","    ensemble_preds = []\n","    \n","    resnet50_model.eval()\n","    efficientnet_b0_model.eval()\n","    inception_v3_model.eval()\n","    \n","    with torch.no_grad():\n","        for data in loader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            resnet50_outputs = resnet50_model(images)\n","            efficientnet_b0_outputs = efficientnet_b0_model(images)\n","            inception_v3_outputs = inception_v3_model(images)\n","            \n","            # Softmax 함수 적용하여 정규화\n","            resnet50_probabilities = nn.functional.softmax(resnet50_outputs, dim=1)\n","            efficientnet_b0_probabilities = nn.functional.softmax(efficientnet_b0_outputs, dim=1)\n","            inception_v3_probabilities = nn.functional.softmax(inception_v3_outputs, dim=1)\n","            \n","            # 가중치 적용하여 확률값 결합\n","            ensemble_probabilities = sum(weight * prob for weight, prob in zip(weights, [resnet50_probabilities, efficientnet_b0_probabilities, inception_v3_probabilities]))\n","            \n","            preds = torch.argmax(ensemble_probabilities, dim=1)\n","            \n","            y_true.extend(labels.tolist())\n","            ensemble_preds.extend(preds.tolist())\n","    \n","    cm = confusion_matrix(y_true, ensemble_preds)\n","    return cm\n","\n","# 가중치 탐색 함수\n","def weight_search(resnet50_model, efficientnet_b0_model, inception_v3_model, loader):\n","    best_accuracy = 0\n","    best_weights = None\n","    best_metrics = None\n","\n","    # 가중치 범위 설정 (0.3 ~ 0.7)\n","    weight_range = np.arange(0.2, 0.81, 0.05)\n","    for resnet50_weight in weight_range:\n","        for efficientnet_b0_weight in weight_range:\n","            inception_v3_weight = 1 - (resnet50_weight + efficientnet_b0_weight)\n","            # 주어진 가중치로 평가\n","            weights = [resnet50_weight, efficientnet_b0_weight, inception_v3_weight]\n","            cm = confusion(resnet50_model, efficientnet_b0_model, inception_v3_model, loader, weights)\n","            accuracy, recall, precision, f1 = metrics(cm)\n","            # 최고 accuracy 갱신\n","            if accuracy > best_accuracy:\n","                best_accuracy = accuracy\n","                best_weights = weights\n","                best_metrics = (accuracy, recall, precision, f1)\n","\n","    return best_weights, best_metrics\n","\n","# metrics 계산 함수\n","def metrics(cm):\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","    recall = (tp) / (tp + fn)\n","    precision = (tp) / (tp + fp)\n","    f1 = (2 * recall * precision) / (recall + precision)\n","\n","    return accuracy, recall, precision, f1\n","\n","# 최적 가중치 탐색\n","best_weights, best_metrics = weight_search(resnet50_model, efficientnet_b0_model, inception_v3_model, test_dataloader)\n","best_resnet50_weight, best_efficientnet_b0_weight, best_inception_v3_weight = best_weights\n","\n","# 최적 가중치로 confusion matrix 계산\n","cm = confusion(resnet50_model, efficientnet_b0_model, inception_v3_model, test_dataloader, best_weights)\n","\n","# 최적 가중치와 confusion matrix 출력\n","print(f\"Best Weights: ResNet50 = {best_resnet50_weight:.2f}, EfficientNet-B0 = {best_efficientnet_b0_weight:.2f}, Inception-v3 = {best_inception_v3_weight:.2f}\")\n","print(cm)\n","\n","# 최적 가중치로 계산된 metrics 출력\n","accuracy, recall, precision, f1 = best_metrics\n","print(f'accuracy: {accuracy:.4f}, recall: {recall:.4f}, precision: {precision:.4f}, f1: {f1:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","# confusion matrix\n","def confusion(resnet50_model, efficientnet_b0_model, inception_v3_model, loader, weights):\n","    y_true = []\n","    ensemble_preds = []\n","    resnet50_model.eval()\n","    efficientnet_b0_model.eval()\n","    inception_v3_model.eval()\n","    with torch.no_grad():\n","        for data in loader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            resnet50_outputs = resnet50_model(images)\n","            efficientnet_b0_outputs = efficientnet_b0_model(images)\n","            inception_v3_outputs = inception_v3_model(images)\n","            # Softmax \n","            resnet50_probabilities = nn.functional.softmax(resnet50_outputs, dim=1)\n","            efficientnet_b0_probabilities = nn.functional.softmax(efficientnet_b0_outputs, dim=1)\n","            inception_v3_probabilities = nn.functional.softmax(inception_v3_outputs, dim=1)\n","            ensemble_probabilities = (weights[0] * resnet50_probabilities) + (weights[1] * efficientnet_b0_probabilities) + (weights[2] * inception_v3_probabilities)\n","            preds = torch.argmax(ensemble_probabilities, dim=1)\n","            y_true.extend(labels.tolist())\n","            ensemble_preds.extend(preds.tolist())\n","    cm = confusion_matrix(y_true, ensemble_preds)\n","    return cm\n","\n","# confusion matrix\n","weights = [0.25, 0.25, 0.50]  # ResNet50, EfficientNet-B0, Inception-v3 모델의 가중치\n","cm = confusion(resnet50_model, efficientnet_b0_model, inception_v3_model, test_dataloader, weights)\n","print(cm)\n","\n","# metrics\n","def metrics(cm):\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","    recall = (tp) / (tp + fn)\n","    precision = (tp) / (tp + fp)\n","    f1 = (2 * recall * precision) / (recall + precision)\n","    print(f'accuracy: {accuracy:.4f}, recall: {recall:.4f}, precision: {precision:.4f}, f1: {f1:.4f}')\n","    return accuracy, recall, precision, f1\n","\n","# metrics\n","accuracy, recall, precision, f1 = metrics(cm)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
